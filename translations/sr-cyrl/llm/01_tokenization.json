{
  "tutorial": "Основе LLM",
  "technical_concept": "LLM-ови не читају речи — читају токене. Токенизација разлаже текст на подречне делове користећи кодирање парова бајтова (BPE). 'Hello world' постају два токена. Токени су основна јединица коју LLM разуме.",
  "challenge": {
    "task": "Укуцајте било који текст и погледајте како га токенизер разлаже на токене. Пробајте различите ствари: просту реченицу, дугу реч као 'containerization', код као 'System.out.println'.",
    "hint": "Пробајте да упоредите кратке честе речи (мање токена) са дугим техничким речима (више токена)."
  },
  "styles": {
    "sci_fi": {
      "title": "Декодирање сигнала",
      "dialogue": [
        {"character": "Научна официрка Чен", "line": "Команданте, анализирала сам како АРИА обрађује наше преносе. Не чита наше речи као ми — разлаже их на фрагменте зване токени."},
        {"character": "Командант Вега", "line": "Како мислите? Шаљемо текст, одговара текстом."},
        {"character": "Научна официрка Чен", "line": "Да, али између слања и примања АРИА разбија наш текст на фрагменте зване токени. 'Hello world' постаје два токена."},
        {"character": "Командант Вега", "line": "Зашто не користи просто речи?"},
        {"character": "Научна официрка Чен", "line": "Зато што су речи неуредне. Различити језици, сложене речи, код, бројеви... Уместо тога АРИА користи Byte Pair Encoding — научила је најчешће обрасце слова."},
        {"character": "Командант Вега", "line": "Значи то значе 'токени' кад АРИА извештава о потрошњи. Наш последњи пренос је био 56 токена."},
        {"character": "Научна официрка Чен", "line": "Тачно. И АРИА има контекстни прозор — максималан број токена које може да обради одједном. 128.000 токена значи отприлике 300 страна текста."},
        {"character": "Командант Вега", "line": "Да пробам декодер сигнала. Желим да видим како би АРИА прочитала моје преносе."}
      ]
    },
    "office_comedy": {
      "title": "Како Алекс чита ваше имејлове",
      "dialogue": [
        {"character": "Сам (старији програмер)", "line": "Значи истраживао сам како Алекс заправо обрађује наше поруке. Испоставило се да не чита речи као ми."},
        {"character": "Менаџер", "line": "Шта? Пишемо на обичном српском."},
        {"character": "Сам (старији програмер)", "line": "Обичан српски за ВАС. За Алекса се ваша порука исецка на 'токене' — мале делове. 'Hello world' су два токена."},
        {"character": "Менаџер", "line": "То делује... неефикасно?"},
        {"character": "Сам (старији програмер)", "line": "Заправо је генијално. Зове се Byte Pair Encoding. Алекс је научио најчешће комбинације слова и спојио их у токене. 'The' је један токен. 'Containerization' су четири."},
        {"character": "Менаџер", "line": "Да ли је зато на рачуну за API пише 'токени' а не 'речи'?"},
        {"character": "Сам (старији програмер)", "line": "Бинго. Плаћамо по токену. И Алекс има ограничење — 128.000 токена по разговору. То је отприлике 300 страна."},
        {"character": "Менаџер", "line": "Да видим тај токенизер. Желим да знам колико токена коштају моји имејлови."}
      ]
    }
  }
}
